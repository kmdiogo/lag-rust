# lag-rust ğŸ¦€  
Lexical Analyzer Generator (LAG) re-written in Rust (blazingly fast btw ğŸ”¥)

## ğŸ“˜ Overview  
`lag-rust` is a tool for generating lexical analyzers (lexers) from token definitions. 
It parses input files describing tokens, constructs a deterministic finite automaton (DFA), and outputs both a serialized DFA table (in JSON ğŸ“„) and a driver program for tokenizing input (selectable in Python or JavaScript).

## âœ¨ Features  
- Fast lexer generation using Rust âš¡  
- Output driver code in Python or JavaScript
- Produces a JSON file with the DFA for integration or debugging 
- WASM bindings for web usage ğŸŒ  

## âš™ï¸ Usage  

### ğŸ–¥ï¸ CLI  
Compile and run the tool using Cargo ğŸ“¦:  
```bash
cargo build --release  
./target/release/lag-rust --input-file <path/to/your/token_definitions.txt> --output-directory <output/dir> --driver-language <python|javascript>
```

ğŸ”§ CLI Options:
- `--input-file` / `-i`: Path to the input file containing token definitions  
- `--output-directory` / `-o`: Directory where output files will be written  
- `--driver-language` / `-d`: Target language for the generated driver (`python` or `javascript`) â€” defaults to `python`

### ğŸ“Œ Example  
```bash
./target/release/lag-rust -i tokens.txt -o ./out -d javascript
```

ğŸ“¤ This will generate:  
- `out/states.json` (serialized DFA)  
- `out/driver.js` (driver code for lexing)  

## ğŸ“š Library  
You can use `lag-rust` as a library or via WASM ğŸ•¸ï¸. The main API entrypoint is:  
```rust
lag_rust_lib::generate_lexer_program(input_text, input_filepath, driver_language)
```

ğŸ“¦ A pre-built WASM library is published to npm:
- [npmjs.com/package/lag_rust](https://www.npmjs.com/package/lag_rust  )

## ğŸ“‹ Requirements  
- Rust (edition 2021)

## ğŸ› ï¸ Development  
Clone the repo and build it yourself:  
```bash
git clone https://github.com/kmdiogo/lag-rust.git  
cd lag-rust  
cargo build
```

## ğŸ”— Repository  
ğŸŒ [GitHub â€“ kmdiogo/lag-rust](https://github.com/kmdiogo/lag-rust)
